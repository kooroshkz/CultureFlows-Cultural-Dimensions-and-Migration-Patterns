{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026dccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1823ccef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (116, 33)\n",
      "Missing values:\n",
      "lto    10\n",
      "ivr    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load masterdata\n",
    "df = pd.read_csv('src/output/masterdata.csv')\n",
    "\n",
    "# Cultural dimension columns to impute\n",
    "cultural_dims = ['pdi', 'idv', 'mas', 'uai', 'lto', 'ivr']\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "missing_counts = df[cultural_dims].isnull().sum()\n",
    "print(f\"Missing values:\\n{missing_counts[missing_counts > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4797bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After regional imputation: 0 missing values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tk/mv5vqmw57czbp018z22myw380000gp/T/ipykernel_46822/2043651315.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '70.83333333333333' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  result.loc[mask, col] = float(mean_val)\n",
      "/var/folders/tk/mv5vqmw57czbp018z22myw380000gp/T/ipykernel_46822/2043651315.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '19.333333333333332' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  result.loc[mask, col] = float(mean_val)\n",
      "/var/folders/tk/mv5vqmw57czbp018z22myw380000gp/T/ipykernel_46822/2043651315.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '47.166666666666664' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  result.loc[mask, col] = float(mean_val)\n",
      "/var/folders/tk/mv5vqmw57czbp018z22myw380000gp/T/ipykernel_46822/2043651315.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '49.833333333333336' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  result.loc[mask, col] = float(mean_val)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Regional mean imputation for initial filling\n",
    "def regional_mean_imputation(data, group_cols, target_cols):\n",
    "    result = data.copy()\n",
    "    \n",
    "    for col in target_cols:\n",
    "        # Calculate regional means\n",
    "        regional_means = result.groupby(group_cols)[col].mean()\n",
    "        \n",
    "        # Fill missing values with regional means\n",
    "        for group, mean_val in regional_means.items():\n",
    "            if pd.notna(mean_val):\n",
    "                if len(group_cols) == 1:\n",
    "                    mask = (result[group_cols[0]] == group) & (result[col].isna())\n",
    "                else:\n",
    "                    mask = (result[group_cols[0]] == group[0]) & (result[group_cols[1]] == group[1]) & (result[col].isna())\n",
    "                result.loc[mask, col] = float(mean_val)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply regional mean imputation (continent + region)\n",
    "df_regional = regional_mean_imputation(df, ['continent', 'region'], cultural_dims)\n",
    "\n",
    "# If still missing, use continent-level means\n",
    "df_continental = regional_mean_imputation(df_regional, ['continent'], cultural_dims)\n",
    "\n",
    "print(f\"After regional imputation: {df_continental[cultural_dims].isnull().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475a8dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iterative imputation: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Iterative Imputation for refinement\n",
    "# Prepare features for iterative imputation\n",
    "year_cols = [col for col in df.columns if col.isdigit() or col.endswith('_male') or col.endswith('_female')]\n",
    "feature_cols = cultural_dims + year_cols\n",
    "\n",
    "# Select relevant columns and create feature matrix\n",
    "imputation_data = df_continental[feature_cols].copy()\n",
    "\n",
    "# Apply iterative imputer\n",
    "iterative_imputer = IterativeImputer(\n",
    "    estimator=None,  # Uses BayesianRidge by default\n",
    "    max_iter=10,\n",
    "    random_state=42,\n",
    "    initial_strategy='mean'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "imputed_values = iterative_imputer.fit_transform(imputation_data)\n",
    "imputed_df = pd.DataFrame(imputed_values, columns=feature_cols, index=df.index)\n",
    "\n",
    "# Replace cultural dimensions in original dataframe\n",
    "df_final = df.copy()\n",
    "for col in cultural_dims:\n",
    "    df_final[col] = imputed_df[col]\n",
    "\n",
    "print(f\"After iterative imputation: {df_final[cultural_dims].isnull().sum().sum()} missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab5323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated masterdata saved with 116 countries and 33 columns\n"
     ]
    }
   ],
   "source": [
    "# Round cultural dimensions to reasonable precision\n",
    "for col in cultural_dims:\n",
    "    if col in ['lto', 'ivr']:\n",
    "        df_final[col] = df_final[col].round(1)\n",
    "    else:\n",
    "        df_final[col] = df_final[col].round(0).astype(int)\n",
    "\n",
    "# Save updated dataset\n",
    "df_final.to_csv('src/output/masterdata.csv', index=False, quoting=0)\n",
    "print(f\"Updated masterdata saved with {df_final.shape[0]} countries and {df_final.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "print(f\"Final dataset: {df_final.shape}\")\n",
    "print(f\"Missing values: {df_final[cultural_dims].isnull().sum().sum()}\")\n",
    "print(\"âœ“ Data imputation completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
